{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- Install the [Cognite Python SDK](https://github.com/cognitedata/cognite-sdk-python)\n",
    "- Make sure that you have received an API key from http://openindustrialdata.com/ \n",
    "- Set the API key as an environment variable, see instructions in the Cognite Python SDK [github repository](https://github.com/cognitedata/cognite-sdk-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started\n",
    "\n",
    "First, we make the imports we'll need for this mini-intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from cognite import CogniteClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The API key is needed to authenticate\n",
    "Use your API key to authenticate. Make sure that you have first set the API key as an environment variable.\n",
    "\n",
    "Your API key is specific to a project. Now we will work with the data as part of the Open Industrial Data. The project is then called \"publicdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CogniteClient(api_key=os.environ['PUBLICDATA_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in the Cognite Data Platform is structured around assets\n",
    "\n",
    "The data in the Cognite Data Platform is structured by assets, where an asset can be a specific piece of equipment or an equipment type. \n",
    "\n",
    "We'll get all assets with get_assets(). You can also include a description or asset name as a parameter -- see more information in the reference docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = client.assets.get_assets()\n",
    "assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API returns response objects. We have added a .to_pandas() method in the Python SDK which makes it easier to view the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_df = assets.to_pandas()\n",
    "assets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking in the table, we see that assets have names, descriptions, metadata, and an own ID. This ID is generated by Cognite and unique for each asset.\n",
    "\n",
    "But what now? That is a big table and it is hard to know what we are looking at.\n",
    "\n",
    "# How to explore data\n",
    "\n",
    "In order to explore the data, you can:\n",
    "1. Use what you know about the physical system to immediately fetch the relevant data \n",
    "2. Navigate the asset hiearchy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. When you the physical system you can immediately zoom in on the relevant data\n",
    "Looking at the diagram on (TODO: CREATE LINK WITH DIAGRAM), we might want to investigate the scrubber further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following P&IDs are uploaded to the Cognite Data Platform.\n",
    "\n",
    "- PH-25578-P-4110006-001: 1st stage lube oil\n",
    "- PH-25578-P-4110010-001: 1 st stage dry gas seal\n",
    "- PH-25578-P-4110119-001: stage 1 - P & I diagram\n",
    "- PH-ME-P-0151-001: 1 st stage suction cooler\n",
    "- PH-ME-P-0152-001: 1 st stage suction scrubber\n",
    "- PH-ME-P-0153-001: 1 st stage compressor\n",
    "- PH-ME-P-0156-001: 1 st stage compressor. Temperatur and vibration monitoring\n",
    "- PH-ME-P-0156-002: 1 st stage compressor. Temperatur and vibration monitoring\n",
    "- PH-ME-0160-001: 1 st stage discharge cooler \n",
    "\n",
    "We can have a look at the PID for the 1st stage suction scrubber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrubber_file_name = 'PH-ME-P-0153-001'\n",
    "client.files.list_files(name=scrubber_file_name).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now download the file using the file id\n",
    "client.files.download_file(client.files.list_files(name=scrubber_file_name).to_pandas().id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code yourself, you will get a new download url which you can use to look at the P&ID in the browser.\n",
    "\n",
    "Skilled engineers can look at the P&ID and understand how the system works. I asked an engineer and was told that I could look at timeseries for the following: \n",
    "\n",
    "- The scrubber level working setpoint (tag name = 'VAL_23-LIC-92521:Control Module:YR')\n",
    "- The scrubber level measured value (tag name = 'VAL_23-LIC-92521:Z.X.Value')\n",
    "- The scrubber level output (tag name = 'VAL_23-LIC-92521:Z.Y.Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the relevant data for the scrubber level setpoint, measured value, and output.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrubber_level_working_setpoint = 'VAL_23-LIC-92521:Control Module:YR'\n",
    "scrubber_level_measured_value  = 'VAL_23-LIC-92521:Z.X.Value'\n",
    "scrubber_level_output  = 'VAL_23-LIC-92521:Z.Y.Value'\n",
    "all_ts_names = [scrubber_level_working_setpoint, scrubber_level_measured_value, scrubber_level_output]\n",
    "print(all_ts_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to pull data is using the function get_datapoints_frame. See reference documentation, http://cognite-sdk-python.readthedocs.io/en/latest/cognite.html#module-cognite.v05.timeseries.\n",
    "\n",
    "This function gets datapoints for given timeseries all on the same timestamps, saving you from otherwise interpolating to get the timeseries data on the same timestamps.\n",
    "\n",
    "Specifying a start and end time gives you data for the desired time range\n",
    "Granularity of 1 hour pulls a single aggregate value for all data points per hour\n",
    "Providing multiple aggregates pulls data using all the three aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2018, 7, 1)\n",
    "end = '1d-ago'\n",
    "data = client.datapoints.get_datapoints_frame(all_ts_names, start=start, end=end, granularity='1h', aggregates=['average', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the data\n",
    "The data is returned with the timeseries for the different aggregates in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute missing values before plotting the data. Pandas has useful functionality for this, e.g. see https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.fillna.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T = pd.to_datetime(data.timestamp, unit='ms')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(T, data[scrubber_level_working_setpoint+'|average'].values, label='setpoint')\n",
    "plt.plot(T, data[scrubber_level_measured_value+'|average'].values, label='measured value')\n",
    "plt.plot(T, data[scrubber_level_output+'|average'].values, label='level output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wooh, you've made a plot! Now what does this data mean?\n",
    "\n",
    "Background:\n",
    "- The blue line is the desired level in the scrubber. \n",
    "- The orange line is actual, measured value in the scrubber.\n",
    "- The green line is the output from the scrubber to control the level in the scrubber.\n",
    "\n",
    "Ideally, the orange line lies on top of the blue line, i.e. the actual measured value is equal to the desired level in the scrubber. The green line can adjust in order to make sure the measured value matches the desired value.\n",
    "\n",
    "We then see that \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Navigating the asset hierarchy is useful when you don't know what you're looking at\n",
    "\n",
    "We can start by navigating up to the root of the asset hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an asset id from the table above\n",
    "first_row_asset_id = 3111454725058294\n",
    "client.assets.get_asset(first_row_asset_id).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the parentId\n",
    "parent_id = 4650652196144007\n",
    "client.assets.get_asset(parent_id).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool, we found the Valhall plattform asset! Let's look at the parent of that\n",
    "parent_id = 6687602007296940\n",
    "client.assets.get_asset(parent_id).to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We navigated all the way up to the AkerBP project! Note, we could also find that node by including description when getting the asset. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.assets.get_assets(description=\"Aker BP\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the get_assets() query gets the same asset as we found by navigating the asset tree. Now, when we are the top, we can also navigate downward the asset hiearchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the subtree below the root\n",
    "akerbp_asset_id = 6687602007296940\n",
    "akerbp_subtree = client.assets.get_asset_subtree(akerbp_asset_id, depth=4)\n",
    "akerbp_subtree.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot which assets have which parents in the table above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats, you've gotten started using the Cognite Data Platform! What's next?\n",
    "\n",
    "You can find ideas for what to model or explore on http://openindustrialdata.com/.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
